{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting Food-Safety Inspections from the Chicago Dataset - A Tutorial (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. In Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Food Inspection Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Load food inspection data\n",
    "inspections = pd.read_csv(os.path.join(root_path, \"DATA/food_inspections.csv\"))\n",
    "\n",
    "# Create basis for model_data\n",
    "data = inspections.loc[:, [\"inspection_id\", \"license\", \"inspection_date\", \"facility_type\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Pass / Fail Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pass / fail flags\n",
    "data[\"pass_flag\"] = inspections.results.apply(lambda x: 1 if x == \"Pass\" else 0)\n",
    "data[\"fail_flag\"] = inspections.results.apply(lambda x: 1 if x == \"Fail\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Facility Risk Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk flags\n",
    "data[\"risk_1\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 1 (High)\" else 0)\n",
    "data[\"risk_2\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 2 (Medium)\" else 0)\n",
    "data[\"risk_3\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 3 (Low)\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Violation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load violation data\n",
    "values = pd.read_csv(os.path.join(root_path, \"DATA/violation_values.csv\"))\n",
    "counts = pd.read_csv(os.path.join(root_path, \"DATA/violation_counts.csv\"))\n",
    "\n",
    "# Merge with violation data\n",
    "data = pd.merge(data, values, on=\"inspection_id\", how=\"left\")\n",
    "data = pd.merge(data, counts, on=\"inspection_id\", how=\"left\")\n",
    "\n",
    "# Set default to 0\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Past Fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort inspections by date\n",
    "grouped = data.sort_values(by=\"inspection_date\", inplace=True)\n",
    "\n",
    "# Find previous inspections by shifting each license group\n",
    "past_data = data.groupby(\"license\").shift(1)\n",
    "\n",
    "# Add past fails\n",
    "data[\"past_fail\"] = past_data.fail_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Past Violation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's an issue with unfilled NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select past violation values, remove past inspection id\n",
    "past_values = past_data[values.columns].drop(\"inspection_id\", axis=1).add_prefix(\"p\")\n",
    "\n",
    "# Set violation values to 0 for first inspections\n",
    "past_values.fillna(0, inplace=True)\n",
    "\n",
    "# Add past values to model data\n",
    "data = data.join(past_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add past violation counts\n",
    "data[\"past_critical\"] = past_data.critical_count\n",
    "data[\"past_serious\"] = past_data.serious_count\n",
    "data[\"past_minor\"] = past_data.minor_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Since Last Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time since previous inspection\n",
    "deltas = pd.to_datetime(data.inspection_date) - pd.to_datetime(past_data.inspection_date)\n",
    "\n",
    "# Add years since previous inspection\n",
    "data[\"time_since_last\"] = deltas.apply(lambda x: x.days / 365.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Record Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if first record\n",
    "data[\"first_record\"] = data.time_since_last.map(lambda x: 1 if pd.isnull(x) else 0)\n",
    "\n",
    "# Set time since last for first inspections to 2\n",
    "data.time_since_last.fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Business License Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Matching Inspections with Licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load business license data\n",
    "licenses = pd.read_csv(os.path.join(root_path, \"DATA/business_licenses.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business licenses have numbers on end preventing simple match\n",
    "# so using street number instead\n",
    "def get_street_number(address):\n",
    "    return address.split()[0]\n",
    "\n",
    "licenses[\"street_number\"] = licenses.address.apply(get_street_number)\n",
    "inspections[\"street_number\"] = inspections.address.apply(get_street_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match based on DBA name and street number\n",
    "venue_matches = pd.merge(inspections, licenses, left_on=[\"dba_name\", \"street_number\"], right_on=[\"doing_business_as_name\", \"street_number\"])\n",
    "\n",
    "# Match based on license numbers\n",
    "license_matches = pd.merge(inspections, licenses, left_on=\"license\", right_on=\"license_number\")\n",
    "\n",
    "# Join matches, reset index, drop duplicates\n",
    "matches = venue_matches.append(license_matches, sort=False)\n",
    "matches.reset_index(drop=True, inplace=True)\n",
    "matches.drop_duplicates([\"inspection_id\", \"id\"], inplace=True)\n",
    "\n",
    "# Restrict to matches where inspection falls within license period\n",
    "matches = matches.loc[matches.inspection_date.between(matches.license_start_date, matches.expiration_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Filterering by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select retail food establishment inspection IDs\n",
    "retail = matches.loc[matches.license_description == \"Retail Food Establishment\", [\"inspection_id\"]]\n",
    "retail.drop_duplicates(inplace=True)\n",
    "\n",
    "# FILTER: ONLY CONSIDER INSPECTIONS MATCHED WITH RETAIL LICENSES\n",
    "data = pd.merge(data, retail, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Calculating Age at Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime format\n",
    "matches.inspection_date = pd.to_datetime(matches.inspection_date)\n",
    "matches.license_start_date = pd.to_datetime(matches.license_start_date)\n",
    "\n",
    "def get_age_data(group):\n",
    "    min_date = group.license_start_date.min()\n",
    "    deltas = group.inspection_date - min_date\n",
    "    group[\"age_at_inspection\"] = deltas.apply(lambda x: x.days / 365.25)\n",
    "    return group[[\"inspection_id\", \"age_at_inspection\"]]\n",
    "\n",
    "# Calculate (3 mins), drop duplicates\n",
    "age_data = matches.groupby(\"license\").apply(get_age_data).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in age_at_inspection\n",
    "data = pd.merge(data, age_data, on=\"inspection_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Calculating Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate categories to snake-case titles\n",
    "categories = {\n",
    "    \"Consumption on Premises - Incidental Activity\": \"consumption_on_premises_incidental_activity\",\n",
    "    \"Tobacco\": \"tobacco\",\n",
    "    \"Package Goods\": \"package_goods\",\n",
    "    \"Limited Business License\": \"limited_business_license\",\n",
    "    \"Outdoor Patio\": \"outdoor_patio\",\n",
    "    \"Public Place of Amusement\": \"public_place_of_amusement\",\n",
    "    \"Children's Services Facility License\": \"childrens_services_facility_license\",\n",
    "    \"Tavern\": \"tavern\",\n",
    "    \"Regulated Business License\": \"regulated_business_license\",\n",
    "    \"Filling Station\": \"filling_station\",\n",
    "    \"Caterer's Liquor License\": \"caterers_liquor_license\",\n",
    "    \"Mobile Food License\": \"mobile_food_license\"\n",
    "}\n",
    "\n",
    "# Create binary markers for license categories\n",
    "def get_category_data(group):\n",
    "    df = group[[\"inspection_id\"]].iloc[[0]]\n",
    "    for category in group.license_description:\n",
    "        if category in categories:\n",
    "            df[categories[category]] = 1\n",
    "    return df\n",
    "    \n",
    "# group by inspection, get categories (2 mins)\n",
    "category_data = matches.groupby(\"inspection_id\").apply(get_category_data)\n",
    "\n",
    "# Reset index, set absent categories to 0\n",
    "category_data.reset_index(drop=True, inplace=True)\n",
    "category_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in category data\n",
    "data = pd.merge(data, category_data, on=\"inspection_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observation datasets\n",
    "burglaries = pd.read_csv(os.path.join(root_path, \"DATA/burglaries.csv\"))\n",
    "carts = pd.read_csv(os.path.join(root_path, \"DATA/garbage_carts.csv\"))\n",
    "complaints = pd.read_csv(os.path.join(root_path, \"DATA/sanitation_complaints.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime columns\n",
    "inspections[\"datetime\"] = pd.to_datetime(inspections.inspection_date)\n",
    "burglaries[\"datetime\"] = pd.to_datetime(burglaries.date)\n",
    "carts[\"datetime\"] = pd.to_datetime(carts.creation_date)\n",
    "complaints[\"datetime\"] = pd.to_datetime(complaints.creation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER: consider only inspections since 2012\n",
    "# Otherwise early inspections have few/no observations within window\n",
    "inspections = inspections.loc[inspections.inspection_date >= \"2012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "\n",
    "def get_kde(observations, column_name, window, bandwidth):\n",
    "\n",
    "    # Sort chronologically and index by datetime\n",
    "    observations.sort_values(\"datetime\", inplace=True)\n",
    "    observations.index = observations.datetime.values\n",
    "    \n",
    "    # Generate kernel from 90 days of observations\n",
    "    def get_kde_given_date(group):\n",
    "        stop = group.datetime.iloc[0]\n",
    "        start = stop - timedelta(days=window)\n",
    "        recent = observations.loc[start:stop]\n",
    "        \n",
    "        x1 = recent.longitude\n",
    "        y1 = recent.latitude\n",
    "        values = np.vstack([x1, y1])\n",
    "        kernel = stats.gaussian_kde(values)\n",
    "\n",
    "        x2 = group.longitude\n",
    "        y2 = group.latitude\n",
    "        samples = np.vstack([x2, y2])\n",
    "        group[column_name] = kernel(samples)\n",
    "        return group[[\"inspection_id\", column_name]]\n",
    "\n",
    "    # Group inspections by date, generate kernels, sample\n",
    "    return inspections.groupby(\"inspection_date\").apply(get_kde_given_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate burglary density estimates\n",
    "burglary_kde = get_kde(burglaries, \"burglary_kde\", 90, 1)\n",
    "\n",
    "# Calculate garbage cart density estimates\n",
    "cart_kde = get_kde(carts, \"cart_kde\", 90, 1)\n",
    "\n",
    "# Calculate sanitation complaint density estimates\n",
    "complaint_kde = get_kde(complaints, \"complaint_kde\", 90, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER: only consider data since 2012 (with good kde data)\n",
    "data = pd.merge(data, burglary_kde, on=\"inspection_id\")\n",
    "data = pd.merge(data, cart_kde, on=\"inspection_id\")\n",
    "data = pd.merge(data, complaint_kde, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "weather = pd.read_csv(os.path.join(root_path, \"DATA/weather.csv\"))\n",
    "\n",
    "# Merge weather data with model data\n",
    "data = pd.merge(data, weather, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRZ0Gd9aQwBv"
   },
   "source": [
    "## 3. Calculation of Model Data\n",
    "We then set out derive all features originally considered by the Chicago team plus several novel features, translating from R to Python in the process. While relative weights in forecasting individual violations rather than number of critical violations may be different, we expect the significant databases and [NEEDS REPHRASING & STUFF]\n",
    "\n",
    "[MAYBE HAVE BULLET POINTS FOR DATABASES, FEATURES]\n",
    "\n",
    "Each row of the final training dataset represents an inspection, its outcomes, and a number of other features. [SOMETHING ABOUT TRAINING METHODOLOGY, MAYBE ABOUT FIGURING OUT WHICH FEATURES MATTER FOR WHICH]\n",
    "\n",
    "We used the inspections database as the basis for our training data.\n",
    "\n",
    "List of features is as follows:\n",
    "\n",
    "### 3.1. features from food inspection data\n",
    "[NEED TO WRITE THIS UP]\n",
    "* used subset of inspections as basis\n",
    "* merged with violation values & counts on inspection id\n",
    "* created pass / fail flags\n",
    "* sorted by date, shifted to get previous info\n",
    "  * past fail\n",
    "  * past critical, serious, minor\n",
    "  * inspections with no past default to 0\n",
    "* calculate time since last\n",
    "  * binary first_record\n",
    "  * time since last defaults to 2\n",
    "  \n",
    "### 3.2. features from business license data\n",
    "[YET TO BE CALCULATED]\n",
    "  \n",
    "### 3.3. from heat maps\n",
    "[YET TO BE CALCULATED]\n",
    "  \n",
    "### 3.4. from weather\n",
    "[YET TO BE CALCULATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating Model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "publication_1",
   "provenance": [
    {
     "file_id": "1cr478KRLrD-8amy4zC7yPwnQfaPFcpts",
     "timestamp": 1529284676149
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
