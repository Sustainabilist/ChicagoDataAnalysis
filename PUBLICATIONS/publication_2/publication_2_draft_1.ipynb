{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting Food-Safety Inspections from the Chicago Dataset - A Tutorial (Part 2)\n",
    "David Lewis, Russell Hofvendahl, Jason Trager\n",
    "* I switched name order here and put my bio second at the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Foreward\n",
    "* probably touch this up\n",
    "\n",
    "Sustainabilist often works on data that is related to quality assurance and control (QA/QC) inspections of public or private infrastructure. Typically, this infrastructure takes the form of solar energy systems or energy efficiency upgrades for buildings. These data sets almost exclusively belong to private entities that have commissioned a study to evaluate how safe and/or well-installed the infrastructure that they financed is. For this reason, it has been very difficult to put anything up in the public sphere about how our work is conducted and any public documentation of what kind of analysis we do.\n",
    "\n",
    "Enter Epicodus, a coding bootcamp in Portland, OR. Several weeks ago, I met David and Russell - two eager coding students who were just learning how to code. They were attending the first meeting of CleanWeb Portland’s first meeting, which Sustainabilist organized. We were talking about the lack of public datasets in sustainability, and I mentioned how Chicago’s food science data set was very similar to many of the QA/QC data sets that I have looked at. Just like that, a project was born.\n",
    "\n",
    "The coding work demonstrated herein is 100% that of the student interns, under my guidance for how to structure, examine, and explore the data. The work was conducted using Google Collaboratory, iPython notebooks, and Anaconda’s scientific computing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review\n",
    "* foreward?\n",
    "* To prevent foodborne illness inspectors enforce stringent food codes, sometimes with the help of predictive violation models\n",
    "* We seek to expand the work of the CDPH, exploring highres predictions and neural nets\n",
    "* We want to to focus on helping restaurants prevent illness and avoid costly violations\n",
    "* We cleaned and pre-processed data from the following sources (databases)\n",
    "* ...(probably more stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering\n",
    "* something on how the model works, what we're building it for, the thing about blinding the model to outcome and then comparing it to actual outcome\n",
    "* how by training model to guess outcome for canvass inspections we're building a tool that we can feed same paramaters at any time to guess outcome of a simulated canvass inspection\n",
    "* Somthing on feature selection, why it makes sense to try out what we're trying out\n",
    "* should we explain features here or below? idk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Food Inspection Features\n",
    "* load inspections and select what we want from it to use as basis for model data\n",
    "* Something on what this data is, where it comes from, why we're using it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Load food inspection data\n",
    "inspections = pd.read_csv(os.path.join(root_path, \"DATA/food_inspections.csv\"))\n",
    "\n",
    "# Create basis for model_data\n",
    "data = inspections.loc[:, [\"inspection_id\", \"license\", \"inspection_date\", \"facility_type\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Pass / Fail Flags\n",
    "* pass fail flags denote inspection outcome, this is something that will be \"covered\" so model can guess it\n",
    "* converted to individual presence/absence flags to help with something or other (what and why specifically?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pass / fail flags\n",
    "data[\"pass_flag\"] = inspections.results.apply(lambda x: 1 if x == \"Pass\" else 0)\n",
    "data[\"fail_flag\"] = inspections.results.apply(lambda x: 1 if x == \"Fail\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Facility Risk Flags\n",
    "* Facilities like restaurants pose greater risk than packaged food kiosks and are given higher risk levels\n",
    "* Higher risk levels mean greater inspection frequency also (unsure if this is relevant)\n",
    "* Again converted to numeric form to fit with (specs? what?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk flags\n",
    "data[\"risk_1\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 1 (High)\" else 0)\n",
    "data[\"risk_2\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 2 (Medium)\" else 0)\n",
    "data[\"risk_3\"] = inspections.results.apply(lambda x: 1 if x == \"Risk 3 (Low)\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Violation Data\n",
    "* Violation data is also something the model will be guessing, another part of the inspection outcome\n",
    "* The data consists of a bunch of rows (representing inspection outcomes) with binary values for whether a specific health code was violated in that inspection\n",
    "* Merged on inspection ID (each row of data is matched and merged with a violation data row with same ID. rows with no matches are excluded.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load violation data\n",
    "values = pd.read_csv(os.path.join(root_path, \"DATA/violation_values.csv\"))\n",
    "counts = pd.read_csv(os.path.join(root_path, \"DATA/violation_counts.csv\"))\n",
    "\n",
    "# Merge with violation data, filtering missing data\n",
    "data = pd.merge(data, values, on=\"inspection_id\")\n",
    "data = pd.merge(data, counts, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Past Fails\n",
    "* Passed fails refers to the previous inspection outcome for that license (as a binary flag)\n",
    "* This is a strong predictor of inspection outcomes\n",
    "* Passed fails is something the model will have access to when predicting inspection outcomes, and will be used to guess the actual and current outcome.\n",
    "* We first create a dataframe of past data by arranging inspections chronologically, grouping by license and shifting each group of inspections by 1, so that the data for each inspection lines up with the row of the next inspection (the first row for each license will by empty and the last inspection is not used). The pre-grouping order is preserved upon shifting.\n",
    "* (this could use visualization)\n",
    "* We can then simply attach the fail_flag column to our data as past fails, setting the empty first value as 0 (no previous fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort inspections by date\n",
    "grouped = data.sort_values(by=\"inspection_date\", inplace=True)\n",
    "\n",
    "# Find previous inspections by shifting each license group\n",
    "past_data = data.groupby(\"license\").shift(1)\n",
    "\n",
    "# Add past fails, with 0 for first inspections\n",
    "data[\"past_fail\"] = past_data.fail_flag.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Past Violation Data\n",
    "* individual past violation values might well be good for predicting individual violations (eg watch out mr. restaurant, you violated these codes last inspection so you're at risk for them)\n",
    "* We can use the same past_data to get past violation values\n",
    "* We'll modify the names to pv_1, etc\n",
    "* If we drop inspection_id we can just tack them on to the end of the data using join\n",
    "* first records are set to 0 (no past violation)\n",
    "* For past_critical, past_serious and past_minor we can similarly just grab each column and add it as a new column in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select past violation values, remove past inspection id\n",
    "past_values = past_data[values.columns].drop(\"inspection_id\", axis=1).add_prefix(\"p\")\n",
    "\n",
    "# Add past values to model data, with 0 for first records\n",
    "data = data.join(past_values.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add past violation counts, with 0 for first records\n",
    "data[\"past_critical\"] = past_data.critical_count.fillna(0)\n",
    "data[\"past_serious\"] = past_data.serious_count.fillna(0)\n",
    "data[\"past_minor\"] = past_data.minor_count.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Time Since Last\n",
    "* One potential risk factor is greater time since last inspection (do we say we got this from Chicago team or just give our own justification?)\n",
    "* To access this convert each inspection date to a python datetime, subtract the previous datetime from the later to create a series of delta objects and convert to days.\n",
    "* the default is set to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time since previous inspection\n",
    "deltas = pd.to_datetime(data.inspection_date) - pd.to_datetime(past_data.inspection_date)\n",
    "\n",
    "# Add years since previous inspection (default to 2)\n",
    "data[\"time_since_last\"] = deltas.apply(lambda x: x.days / 365.25).fillna(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. First Record\n",
    "* Actually not sure why this would matter in predicting outcomes? (check)\n",
    "* Maybe first records are more likely to fail?\n",
    "* To get it we simply put 1s for rows where data is absent in the shifted past_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if first record\n",
    "data[\"first_record\"] = past_data.inspection_id.map(lambda x: 1 if pd.isnull(x) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Business License Features\n",
    "* These are the features derived from the busuiness license dataset\n",
    "* What is a business license? other background info?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Matching Inspections with Licenses\n",
    "* Load data, see publication 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load business license data\n",
    "licenses = pd.read_csv(os.path.join(root_path, \"DATA/business_licenses.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to link food inspections to the business licenses of the facilities inspected we create a table of matches, each linking an inspection to a license\n",
    "* Many business licenses can be matched by license number to an inspection, but to account for licence discrepancies we also matched based on venue (street address and name)\n",
    "* Due to formatting differences it was necessary to use only the street number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business licenses have numbers on end preventing simple match\n",
    "# so using street number instead\n",
    "def get_street_number(address):\n",
    "    return address.split()[0]\n",
    "\n",
    "licenses[\"street_number\"] = licenses.address.apply(get_street_number)\n",
    "inspections[\"street_number\"] = inspections.address.apply(get_street_number)\n",
    "\n",
    "# Match based on DBA name and street number\n",
    "venue_matches = pd.merge(inspections, licenses, left_on=[\"dba_name\", \"street_number\"], right_on=[\"doing_business_as_name\", \"street_number\"])\n",
    "\n",
    "# Match based on license numbers\n",
    "licence_matches = pd.merge(inspections, licenses, left_on=\"license\", right_on=\"license_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* to create the working matches dataset we then appended venue and licence matches and dropped any duplicate inspection / business licence matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join matches, reset index, drop duplicates\n",
    "matches = venue_matches.append(license_matches, sort=False)\n",
    "matches.reset_index(drop=True, inplace=True)\n",
    "matches.drop_duplicates([\"inspection_id\", \"id\"], inplace=True)\n",
    "\n",
    "# Restrict to matches where inspection falls within license period\n",
    "matches = matches.loc[matches.inspection_date.between(matches.license_start_date, matches.expiration_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Filterering by Category\n",
    "* (This isn't a feature but is only convenient to do once we have the matches dataset. what to do?)\n",
    "* many non-retail establishments eg schools, hospitals follow different inspection schedules, so to ensure consistent data we filter matches to include only inspections of retail food establishments\n",
    "* to do this we select the inspection id's of all retail matches, drop any duplicates and merge these id's with the model data\n",
    "* by default merge includes only rows with keys present in each dataset (inner join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select retail food establishment inspection IDs\n",
    "retail = matches.loc[matches.license_description == \"Retail Food Establishment\", [\"inspection_id\"]]\n",
    "retail.drop_duplicates(inplace=True)\n",
    "\n",
    "# FILTER: ONLY CONSIDER INSPECTIONS MATCHED WITH RETAIL LICENSES\n",
    "data = pd.merge(data, retail, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Calculating Age at Inspection\n",
    "* What might age at inspection tell?\n",
    "* One feature previously found significant in predicting inspection outcomes is the age of the facility\n",
    "* To calculate this we first convert all dates to datetime objects\n",
    "* We then group by licence and within each group find the earliest license start date\n",
    "* Finally we subtract this min date from the inspection date and merge the resulting age in with our model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime format\n",
    "matches.inspection_date = pd.to_datetime(matches.inspection_date)\n",
    "matches.license_start_date = pd.to_datetime(matches.license_start_date)\n",
    "\n",
    "def get_age_data(group):\n",
    "    min_date = group.license_start_date.min()\n",
    "    deltas = group.inspection_date - min_date\n",
    "    group[\"age_at_inspection\"] = deltas.apply(lambda x: x.days / 365.25)\n",
    "    return group[[\"inspection_id\", \"age_at_inspection\"]]\n",
    "\n",
    "# Calculate (3 mins), drop duplicates\n",
    "age_data = matches.groupby(\"license\").apply(get_age_data).drop_duplicates()\n",
    "\n",
    "# Merge in age_at_inspection\n",
    "data = pd.merge(data, age_data, on=\"inspection_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Calculating Category Data\n",
    "* The chicago team found the categories of licences attributed to an establishment to be significant in predicting violation outcomes\n",
    "* This data is derived from the licence_description column of the business licences dataset\n",
    "* We will be noting the presence or absence of these categories as a series of binary flags\n",
    "* To derive these features we first set up a dictionary linking the column entries to our desired snake case column titles\n",
    "* We then group matches by inspection id to gather all licence descriptions for each inspection\n",
    "* To generate the entries we apply our get_category_data method, using our dictionary to translate from licence_description entries to column titles\n",
    "* Finally we fill missing entries as 0 and merge the results in with our model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate categories to snake-case titles\n",
    "categories = {\n",
    "    \"Consumption on Premises - Incidental Activity\": \"consumption_on_premises_incidental_activity\",\n",
    "    \"Tobacco\": \"tobacco\",\n",
    "    \"Package Goods\": \"package_goods\",\n",
    "    \"Limited Business License\": \"limited_business_license\",\n",
    "    \"Outdoor Patio\": \"outdoor_patio\",\n",
    "    \"Public Place of Amusement\": \"public_place_of_amusement\",\n",
    "    \"Children's Services Facility License\": \"childrens_services_facility_license\",\n",
    "    \"Tavern\": \"tavern\",\n",
    "    \"Regulated Business License\": \"regulated_business_license\",\n",
    "    \"Filling Station\": \"filling_station\",\n",
    "    \"Caterer's Liquor License\": \"caterers_liquor_license\",\n",
    "    \"Mobile Food License\": \"mobile_food_license\"\n",
    "}\n",
    "\n",
    "# Create binary markers for license categories\n",
    "def get_category_data(group):\n",
    "    df = group[[\"inspection_id\"]].iloc[[0]]\n",
    "    for category in group.license_description:\n",
    "        if category in categories:\n",
    "            df[categories[category]] = 1\n",
    "    return df\n",
    "    \n",
    "# group by inspection, get categories (2 mins)\n",
    "category_data = matches.groupby(\"inspection_id\").apply(get_category_data)\n",
    "\n",
    "# Reset index, set absent categories to 0\n",
    "category_data.reset_index(drop=True, inplace=True)\n",
    "category_data.fillna(0, inplace=True)\n",
    "\n",
    "# Merge in category data, fill nan with 0\n",
    "data = pd.merge(data, category_data, on=\"inspection_id\", how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Density Estimates for Crime, Garbage Carts, Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observation datasets\n",
    "burglaries = pd.read_csv(os.path.join(root_path, \"DATA/burglaries.csv\"))\n",
    "carts = pd.read_csv(os.path.join(root_path, \"DATA/garbage_carts.csv\"))\n",
    "complaints = pd.read_csv(os.path.join(root_path, \"DATA/sanitation_complaints.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime columns\n",
    "inspections[\"datetime\"] = pd.to_datetime(inspections.inspection_date)\n",
    "burglaries[\"datetime\"] = pd.to_datetime(burglaries.date)\n",
    "carts[\"datetime\"] = pd.to_datetime(carts.creation_date)\n",
    "complaints[\"datetime\"] = pd.to_datetime(complaints.creation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER: consider only inspections since 2012\n",
    "# Otherwise early inspections have few/no observations within window\n",
    "inspections = inspections.loc[inspections.inspection_date >= \"2012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "\n",
    "def get_kde(observations, column_name, window, bandwidth):\n",
    "\n",
    "    # Sort chronologically and index by datetime\n",
    "    observations.sort_values(\"datetime\", inplace=True)\n",
    "    observations.index = observations.datetime.values\n",
    "    \n",
    "    # Generate kernel from 90 days of observations\n",
    "    def get_kde_given_date(group):\n",
    "        stop = group.datetime.iloc[0]\n",
    "        start = stop - timedelta(days=window)\n",
    "        recent = observations.loc[start:stop]\n",
    "        \n",
    "        x1 = recent.longitude\n",
    "        y1 = recent.latitude\n",
    "        values = np.vstack([x1, y1])\n",
    "        kernel = stats.gaussian_kde(values)\n",
    "\n",
    "        x2 = group.longitude\n",
    "        y2 = group.latitude\n",
    "        samples = np.vstack([x2, y2])\n",
    "        group[column_name] = kernel(samples)\n",
    "        return group[[\"inspection_id\", column_name]]\n",
    "\n",
    "    # Group inspections by date, generate kernels, sample\n",
    "    return inspections.groupby(\"inspection_date\").apply(get_kde_given_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate burglary density estimates\n",
    "burglary_kde = get_kde(burglaries, \"burglary_kde\", 90, 1)\n",
    "\n",
    "# Calculate garbage cart density estimates\n",
    "cart_kde = get_kde(carts, \"cart_kde\", 90, 1)\n",
    "\n",
    "# Calculate sanitation complaint density estimates\n",
    "complaint_kde = get_kde(complaints, \"complaint_kde\", 90, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER: only consider data since 2012 (with good kde data)\n",
    "data = pd.merge(data, burglary_kde, on=\"inspection_id\")\n",
    "data = pd.merge(data, cart_kde, on=\"inspection_id\")\n",
    "data = pd.merge(data, complaint_kde, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "weather = pd.read_csv(os.path.join(root_path, \"DATA/weather.csv\"))\n",
    "\n",
    "# Merge weather data with model data\n",
    "data = pd.merge(data, weather, on=\"inspection_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Russell Hofvendahl is a web application developer with a great fondness for data driven decision making. Russell is excited to explore the applications of data science and machine learning in improving human judgement.\n",
    "* David Lewis is a seasoned corporate responsibility professional working to utilize technology to help improve the health and well being of human populations through environmental stewardship.\n",
    "* Jason S. Trager, Ph.D. is the managing partner at Sustainabilist and an expert in process improvement for distributed systems. Jason’s work portfolio includes the creation of novel data-driven methods for improving contractor performance, machine learning to optimize value in energy efficiency sales, and equipment maintenance optimization methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "publication_1",
   "provenance": [
    {
     "file_id": "1cr478KRLrD-8amy4zC7yPwnQfaPFcpts",
     "timestamp": 1529284676149
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
